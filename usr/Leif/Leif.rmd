---
title: "Untitled"
author: "Leif Watkins"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)  # Load core packages
library(MASS)       # LDA, QDA, OLS, Ridge Regression, Box-Cox, stepAIC, etc,.
library(e1071)      # Naive Bayesian Classfier,SVM, GKNN, ICA, LCA
library(class)      # KNN, SOM, LVQ
library(ROCR)       # Precision/Recall/Sensitivity/Specificity performance plot 
library(boot)       # LOOCV, Bootstrap,
set.seed(1234)
```



#get the white wine data and clean it . 
```{r}
data <- read.csv("data\\winequality-white.csv", sep = ";", header = T)

# this is to convert the quality predictor from numerical into categorical
wine_data <-  data %>% mutate(good = ifelse(quality>=7, 1, 0))
wine_data$quality <- NULL

wine_data <- wine_data[!duplicated(wine_data), ]

head(wine_data)
```

#looking in to the data we are working with 
```{r}
str(wine_data)


### spiting the data into train and test sets


### Data Split
#splitting the dataset into train and test (2/3rd for train remaining for test)
inTrain <- caret::createDataPartition(wine_data$good, p = 7/10, list = F)
train <- wine_data[inTrain,]
test <- wine_data[-inTrain,]


train$good <- as.factor(train$good)
test$good <- as.factor(test$good)

```

# fitting a logistic regression 
```{r}

#wine_glm<- glm(good ~ . ,wine_data)
#summary(wine_glm)

#w2_glm <- glm(good ~ . -citric.acid, data = wine_data )
#w2_glm <- logit(good ~ . -citric.acid, data = wine_data )
#w2_glm$residuals
#summary(w2_glm)

```




### qda 
```{r}

### THE OLD WAY OF DOING IT
set.seed(1234)
qda.fit = qda(good ~ . , data = train, family = binomial)
qda.fit
# 
# 
set.seed(1234)
qda.pred  = predict(qda.fit, test)
names(qda.pred)
qda.class = qda.pred$class
length(test$good)
length(qda.class)
#      truth   , prediction
#table(qda.class, test$good )
table(test$good, qda.class )

#caret::confusionMatrix(qda.class, test$good )

#### using caret package
library(caret)

set.seed(1234)
train_qda <- trainControl(method = "cv", number = 10 )
set.seed(1234)
wine_qda <- train(good ~ . , data = train , method = "qda", trControl = train_qda)

#predictions
qda_pred <- predict(wine_qda, newdata= test)
caret::confusionMatrix(test$good ,qda_pred)



# # ROCR #
# qda.pred <- prediction(qda.pred$posterior[,2], Smarket.2005$Direction) 
# qda.perf <- performance(qda.pred,"tpr","fpr")
# plot(qda.perf,colorize=TRUE, lwd = 2)
# abline(a = 0, b = 1) 
# 
# 
# qda.auc = performance(qda.pred, measure = "auc")
# print(qda.auc@y.values)
# 
# 
# results.matrix[3,] = as.numeric( c(spec.qda, sen.qda, oer.qda1, qda.auc@y.values))
# 
# 

```



#### LDA  
```{r}
###### caret
# set.seed(1234)
# train_lda <- trainControl(method = "cv", repeats = 10 )
# set.seed(1234)
# wine_lda <- train(good ~ . , data = train , method = "lda", trControl = train_lda)
# 
# #predictions
# lda_pred <- predict(wine_lda, newdata= test)
# caret::confusionMatrix(lda_pred, test$good )

######### base R










lda.fit = qda(good ~ . , data = train, family = binomial)
lda.fit
# 
# 
set.seed(1234)
lda.pred  = predict(lda.fit, test)
names(lda.pred)
lda.class = lda.pred$class
length(test$good)
length(lda.class)
#      truth   , prediction
#table(qda.class, test$good )
#table(test$good, qda.class )


set.seed(1234)
my_oer <- list()

for (i in 1:10){
  train_data <- wine_data[-((i*396-395):(i*396)), ]
  test_data <- wine_data[((i*396-395):(i*396)), ]
  lda.fit = lda(good ~ . , data = train, family = binomial)
  m_pred <- predict(lda.fit, test_data)
  oer  = 1 - mean(lda.fit == test_data)
  my_oer <- append(oer)

}
my_oer
#test_err_rate=c(MAE, mean(mae))
#MAE


```

