---
title: "Introduction to Statistical Learning"
subtitle: "STAT 387" 
format: 
  html:
    df-print: paged
    theme:
      light: materia
      dark: slate
    toc: true
    toc-title: Table of Contents
    toc-depth: 4
    toc-location: left
    number-sections: false
    number-depth: 3
    anchor-sections: true
    smooth-scroll: true
    link-external-icon: false
    link-external-newwindow: false
    code-fold: false
    code-line-numbers: false
    code-overflow: scroll
    code-tools: 
      source: true
      toggle: true
      caption: none
    code-summary: "Show/Hide Code"
    highlight-style: atom-one
    link-external-filter: '^(?:http:|https:)\/\/www\.quarto\.org\/custom'
    self-contained-math: true
    fig-align: center
    html-math-method:
      method: mathjax
      url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.align = TRUE)

library(tidyverse)  # Load core packages: 
# ggplot2,   for data visualization.
# dplyr,     for data manipulation.
# tidyr,     for data tidying.
# purrr,     for functional programming.
# tibble,    for tibbles, a modern re-imagining of data frames.
# stringr,   for strings.
# forcats,   for factors.
# lubridate, for date/times.
# readr,     for reading .csv, .tsv, and .fwf files.
# readxl,    for reading .xls, and .xlxs files.
# feather,   for sharing with Python and other languages.
# haven,     for SPSS, SAS and Stata files.
# httr,      for web apis.
# jsonlite   for JSON.
# rvest,     for web scraping.
# xml2,      for XML.
# modelr,    for modelling within a pipeline
# broom,     for turning models into tidy data
# hms,       for times.

library(magrittr)   # Pipeline operator
library(lobstr)     # Visualizing abstract syntax trees, stack trees, and object sizes
library(pander)     # Exporting/converting complex pandoc documents, EX: df to Pandoc table
library(ggforce)    # More plot functions on top of ggplot2
library(ggpubr)     # Automatically add p-values and significance levels  plots. 
# Arrange and annotate multiple plots on the same page. 
# Change graphical parameters such as colors and labels.
library(sf)         # Geo-spatial vector manipulation: points, lines, polygons
library(kableExtra) # Generate 90 % of complex/advanced/self-customized/beautiful tables
library(cowplot)    # Multiple plots arrangement
library(gridExtra)  # Multiple plots arrangement
library(animation)  # Animated figure container
library(latex2exp)  # Latex axis titles in ggplot2
library(ellipse)    # Simultaneous confidence interval region to check C.I. of 2 slope parameters
library(plotly)     # User interactive plots
library(ellipse)    # Simultaneous confidence interval region to check C.I. of 2 regressors
library(olsrr)      # Model selections 
library(leaps)      # Regression subsetting 
library(pls)        # Partial Least squares
library(MASS)       # LDA, QDA, OLS, Ridge Regression, Box-Cox, stepAIC, etc,.
library(e1071)      # Naive Bayesian Classfier,SVM, GKNN, ICA, LCA
library(class)      # KNN, SOM, LVQ
library(ROCR)       # Precision/Recall/Sensitivity/Specificity performance plot 
library(boot)       # LOOCV, Bootstrap,
library(caret)      # Classification/Regression Training, run ?caret::trainControl
library(corrgram)   # for correlation matrix
library(corrplot)   # for graphical display of correlation matrix

set.seed(1234)        # make random results reproducible

current_dir <- getwd()

if (!is.null(current_dir)) {
  setwd(current_dir)
  remove(current_dir)
}
```

```{css, echo=FALSE}
body {
font-family: "Times New Roman";
font-size: 0.8em;
}

h2, .h2, h2.anchored, 
h3, .h3, h3.anchored,
.quarto-title, 
.quarto-title-meta {
text-align: center;
}

h2, .h2 {
font-size: 1.5em;
}

h3, .h3 {
font-size: 1.25em;
}

h4, .h4 {
font-size: 1em;
}

h5, .h5 {
font-size: 0.75em;
}

h6, .h6 {
font-size: 0.7em;
}

.quarto-title-meta {
display: block!important;
}

.quarto-title-meta-heading {
display: none;
}

.content {
width: 1000px;
}
.dropdown-menu {
font-size: 0.8rem;
}

code {
color: #61AFEF;
}

.btn {
border-color: #f8f9fa9e!important;
}

body.quarto-dark {
background-color: #282c34;

color: #d8dee9;

.pagedtable .even {
background-color: #3b4252!important;
}

p code:not(.sourceCode), li code:not(.sourceCode) {
background-color: #4c566a!important;
}
}

#quarto-code-tools-menu{
position: absolute;
}

.top-right {
position: fixed;
}

#TOC::before {
content: "";
display: block;
height: 141px;
margin: 20px 20px 20px 20px;
background-image: url("https://raw.githubusercontent.com/theRealLeif/STAT387/main/README.asset/Logo.svg");
background-size: contain;
background-position: center center;
background-repeat: no-repeat;
}

```


## Preamble

Consider the wine quality dataset from [UCI Machine Learning Respository](https://archive.ics.uci.edu/ml/datasets/Wine+Quality). We will focus only on the data concerning white wines (and not red wines). Dichotomize the `quality` variable as `good`, which takes the value 1 if quality â‰¥ 7 and the value 0, otherwise. We will take `good` as response and all the 11 physiochemical characteristics of the wines in the data as predictors.

### Problem Statements

Use 10-fold cross-validation for estimating the test error rates below and compute the estimates using `caret` package with seed set to 1234 before each computation.

(a) Fit a KNN with K chosen optimally using test error rate. Report error rate, sensitivity, specificity, and AUC for the optimal KNN based on the training data. Also, report its estimated test error rate.
(b) Repeat (a) using logistic regression.
(c) Repeat (a) using LDA.
(d) Repeat (a) using QDA.
(e) Compare the results in (a)-(d). Which classifier would you recommend? Justify your answer.



### Methodologies
- KNN
- GLM/logit/glmnet
- LDA
- QDA
- Naive Bayes
- Decision Tree
  - Classification and Regression Trees (CART)
- Random Forest (Classification)
- Bagging (Bootstrap Aggregation)
- Boosting (Gradient Boosting Machine (GBM))
- eXtreme Gradient Boosting (XGBoost)
- Extremely Randomized Trees (ExtraTrees)
- SVM
- Neural Networks (NNET)


### Data Description
This is a dataset of wine quality containing 4898 observations of 12 variables. The variables are:

- `fixed.acidity`: The amount of fixed acid in the wine ($g/dm^3$)
- `volatile.acidity`: The amount of volatile acid in the wine ($g/dm^4$)
- `citric.acid`: The amount of citric acid in the wine ($g/dm^3$)
- `residual.sugar`: The amount of residual sugar in the wine ($g/dm^3$)
- `chlorides`: The amount of salt in the wine ($g/dm^3$)
- `free.sulfur.dioxide`: The amount of free sulfur dioxide in the wine ($mg/dm^3$)
- `total.sulfur.dioxide`: The amount of total sulfur dioxide in the wine ($mg/dm^3$)
- `density`: The density of the wine ($g/dm^3$)
- `pH`: The $pH$ value of the wine
- `sulphates`: The amount of sulphates in the wine ($g/dm^3$)
- `alcohol`: The alcohol content of the wine ($\% vol$)
- `quality`: The quality score of the wine (0-10)

After removing the duplicate rows from our data set, we are left with 3961 observations of the above 11 variables minus `quality` column variable, and introduced a new variable `good` as our response:

- `good`: A binary variable indicating whether the wine is good (`quality` $\geq$ 7) or not (`quality` $<$ 7).


## Exploratory Analysis

### Data Import
```{r data_import}
wine.data <- read.csv("dataset\\winequality-white.csv", sep=";", header = T)

wine.data_subset <-  wine.data %>% 
  mutate(good = ifelse(quality>=7, 1, 0)) %>% 
  distinct() %>% 
  dplyr::select(c(1:11, 13))

head(wine.data)
head(wine.data_subset)
```

### Data Analysis
```{r basic_analysis}
dim(wine.data)
dim(wine.data_subset)

str(wine.data)
str(wine.data_subset)

summary(wine.data)
summary(wine.data_subset)

# Check for NAs in dataset
sum(is.na(wine.data))

# Counts at each combination of response's factor levels
table(wine.data$quality)
```

### Data Histograms
```{r hist_plot, warning=FALSE}
wine.colnames <- colnames(wine.data_subset[, 1:12])
num_plots     <- length(wine.colnames)
num_rows      <- ceiling(num_plots/3)


# Create an empty list to store plots
grid_arr      <- list()


# Loop over each column name in the wine.colnames vector
for(i in 1:num_plots) {
  # Create a ggplot object for the current column using aes
  plt <- ggplot(data = wine.data_subset, aes_string(x = wine.colnames[i])) +
    geom_histogram(binwidth = diff(range(wine.data_subset[[wine.colnames[i]]]))/30, 
                   color = "black", fill = "slategray3") +
    labs(x = wine.colnames[i], y = "Frequency") +
    theme_bw()
  
  # Add the current plot to the grid_arr list
  grid_arr[[i]] <- plt
}

grid_arr <- do.call(gridExtra::grid.arrange, c(grid_arr, ncol = 3))
```

```{r, echo=FALSE}
# Remove unnecessary variables
remove(grid_arr)
remove(plt)
remove(i)
remove(num_plots)
remove(num_rows)
```

### Data Relationships
```{r relation_plot, fig.width=10, fig.height=5, message=FALSE}
reshape2::melt(wine.data[, 1:12], "quality") %>% 
  ggplot(aes(value, quality, color = variable)) +  
  geom_point() + 
  geom_smooth(aes(value,quality, colour=variable), method=lm, se=FALSE)+
  facet_wrap(.~variable, scales = "free")

# Collinearity between Attributes
cor(wine.data_subset) %>% 
  corrplot::corrplot(method = 'number',  type = "lower", tl.col = "steelblue", number.cex = 0.5)

# Remove quality from dataset, use good as response 
wine.data_subset$quality <- NULL 
```

### Data Split
```{r data_split}
set.seed(123)
# Splitting the dataset into train and test (7/10th for train remaining for test)
inTrain <- caret::createDataPartition(wine.data_subset$good, p = 7/10, list = F)
train <- wine.data_subset[inTrain,]
test <- wine.data_subset[-inTrain,]


# Convert the outcome variable to a factor with two levels
train$good <- as.factor(train$good)
test$good <- as.factor(test$good)
```

## Data Modeling

### K-Nearest Neightbor

#### Model Construction
```{r knn.model_savings, eval=FALSE}
#--------------------#
#-----K-fold CV------#
#--------------------#

set.seed(1234)
# Define the training control object for 10-fold cross-validation
train_control <- trainControl(method = "cv", number = 10)

# Train the KNN model using 10-fold cross-validation
# tuneLength argument to specify the range of values of K to be considered for tuning
set.seed(1234)
knn_model <- train(good ~ ., 
                   data = train, 
                   method = "knn", 
                   trControl = train_control)

# Save the model into .Rdata for future import 
save(knn_model, file = "dataset\\knn.model_kfoldCV.Rdata")


#--------------------------#
#-----K-fold CV (Mod)------#
#--------------------------#

set.seed(1234)
train_control <- trainControl(method = "cv", number = 10)

set.seed(1234)
knn_model <- train(good ~ ., 
                   data = train, 
                   method = "knn", 
                   trControl = train_control, 
                   tuneLength = 10)

# Save the model into .Rdata for future import 
save(knn_model, file = "dataset\\knn.model_kfoldCV_mod.Rdata")


#--------------------#
#----Hold-out CV-----#
#--------------------#

set.seed(1234)
train_control <- trainControl(method = "none",)

set.seed(1234)
knn_model <- train(good ~ ., 
                   data = train, 
                   method = "knn")

save(knn_model, file = "dataset\\knn.model_holdoutCV.Rdata")


#--------------------------#
#----Hold-out CV (Mod)-----#
#--------------------------#

set.seed(1234)
train_control <- trainControl(method = "none",)

set.seed(1234)
knn_model <- train(good ~ ., 
                   data = train, 
                   method = "knn",
                   tuneGrid = expand.grid(k=1:30))

save(knn_model, file = "dataset\\knn.model_holdoutCV_mod.Rdata")


#--------------------#
#-------LOOCV--------#
#--------------------#

set.seed(1234)
train_control <- trainControl(method = "LOOCV")

set.seed(1234)
knn_model <- train(good ~ ., 
                   data = train, 
                   method = "knn", 
                   trControl = train_control)

save(knn_model, file = "dataset\\knn.model_looCV.Rdata")


#--------------------------#
#-------LOOCV (Mod)--------#
#--------------------------#

set.seed(1234)
train_control <- trainControl(method = "LOOCV")

set.seed(1234)
knn_model <- train(good ~ ., 
                   data = train, 
                   method = "knn", 
                   trControl = train_control,
                   tuneLength = 10,
                   tuneGrid = expand.grid(k = 1:20))

save(knn_model, file = "dataset\\knn.model_looCV_mod.Rdata")


#--------------------#
#----Repeated CV-----#
#--------------------#

set.seed(1234)
train_control <- trainControl(method = "repeatedcv", number = 10, repeats = 5)

set.seed(1234)
knn_model <- train(good ~ ., 
                   data = train, 
                   method = "knn", 
                   trControl = train_control)

save(knn_model, file = "dataset\\knn.model_repeatedCV.Rdata")


#--------------------------#
#----Repeated CV (Mod)-----#
#--------------------------#

set.seed(1234)
train_control <- trainControl(method = "repeatedcv", number = 10, repeats = 5)

kknn.grid <- expand.grid(kmax = c(3, 5, 7 ,9, 11), distance = c(1, 2, 3),
                         kernel = c("rectangular", "gaussian", "cos"))

set.seed(1234)
knn_model <- train(good ~ ., 
                   data = train, 
                   method = "kknn",
                   trControl = train_control, 
                   tuneGrid = kknn.grid,
                   preProcess = c("center", "scale"))

save(knn_model, file = "dataset\\knn.model_repeatedCV_mod.Rdata")
```


#### K-fold CV 
```{r knn.kfoldCV, fig.show='hide'}
# Import model
load("dataset\\knn.model_kfoldCV.Rdata")

# Make predictions on the test data using the trained model and calculate the test error rate
knn.predictions <- predict(knn_model, newdata = test)

confusionMatrix(knn.predictions, test$good)


# Convert predictions to a numeric vector
knn.predictions <- as.numeric(knn.predictions)

# Calculate the AUC using the performance() and auc() functions:
pred_obj <- prediction(knn.predictions, test$good)
auc_val <- performance(pred_obj, "auc")@y.values[[1]]
auc_val

# Performance plot for TP and FP
roc_obj <- performance(pred_obj, "tpr", "fpr")
plot(roc_obj, colorize = TRUE, lwd = 2,
     xlab = "False Positive Rate", 
     ylab = "True Positive Rate",
     main = "ROC Curves from 10-fold CV")
points(auc_val, 1 - auc_val, 
       col = "steelblue", 
       pch = 21)
abline(a = 0, b = 1)
knn.kfoldCV.ROC.plot<- recordPlot()

# Accuracy and Kappa value plot
knn.accu.kappa.plot <- function(knn.model) {
  p <- ggplot(data=data.frame(k = knn.model$results$k,
                              Accuracy = knn.model$results$Accuracy,
                              Kappa = knn.model$results$Kappa)) +
    geom_point(aes(x = k, y = Accuracy, color = "Accuracy")) +
    geom_point(aes(x = k, y = Kappa, color = "Kappa")) +
    geom_line(aes(x = k, y = Accuracy, linetype = "Accuracy", color = "Accuracy")) +
    geom_line(aes(x = k, y = Kappa, linetype = "Kappa", color = "Kappa")) +
    scale_color_manual(values = c("#98c379", "#e06c75"),
                       guide = guide_legend(override.aes = list(linetype = c(1, 0)) )) +
    scale_linetype_manual(values=c("solid", "dotted"),
                          guide = guide_legend(override.aes = list(color = c("#98c379", "#e06c75")))) +
    labs(x = "K value", 
         y = "Accuracy / Kappa") +
    ylim(0, 1) +
    theme_bw() +
    theme(plot.title = element_text(hjust = 0.5)) +
    guides(color = guide_legend(title = "Metric"),
           linetype = guide_legend(title = "Metric"))
  return(p)
}

knn.kfoldCV.plot <- knn.accu.kappa.plot(knn_model) + 
  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), vjust = -1) +
  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), vjust = -1) +
  ggtitle("KNN Model Performance (10-Fold CV)")
```

##### Tuned
```{r knn.kfoldCV_mod, fig.show='hide'}
load("dataset\\knn.model_kfoldCV_mod.Rdata")

knn.predictions <- predict(knn_model, newdata = test)

confusionMatrix(knn.predictions, test$good)

knn.predictions <- as.numeric(knn.predictions)
pred_obj <- prediction(knn.predictions, test$good)
auc_val <- performance(pred_obj, "auc")@y.values[[1]]
auc_val

roc_obj <- performance(pred_obj, "tpr", "fpr")
invisible(plot(roc_obj, colorize = TRUE, lwd = 2,
               xlab = "False Positive Rate", 
               ylab = "True Positive Rate",
               main = "ROC Curves from Tuned K-fold CV"))
points(auc_val, 1 - auc_val, 
       col = "steelblue", 
       pch = 21)
abline(a = 0, b = 1)
knn.kfoldCV_mod.ROC.plot <- recordPlot()

knn.kfoldCV_mod.plot <- knn.accu.kappa.plot(knn_model) +
  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), vjust = -1) +
  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), vjust = -1) +
  ggtitle("KNN Model Performance (Tuned 10-Fold CV)")
```


#### Hold-out CV
```{r knn.holdoutCV, fig.show='hide'}
load("dataset\\knn.model_holdoutCV.Rdata")

knn.predictions <- predict(knn_model, newdata = test)

confusionMatrix(knn.predictions, test$good)

knn.predictions <- as.numeric(knn.predictions)
pred_obj <- prediction(knn.predictions, test$good)
auc_val <- performance(pred_obj, "auc")@y.values[[1]]
auc_val

roc_obj <- performance(pred_obj, "tpr", "fpr")
plot(roc_obj, colorize = TRUE, lwd = 2,
     xlab = "False Positive Rate", 
     ylab = "True Positive Rate",
     main = "ROC Curves from Hold-out CV")
points(auc_val, 1 - auc_val, 
       col = "steelblue", 
       pch = 21)
abline(a = 0, b = 1)
knn.holdoutCV.ROC.plot <- recordPlot()

knn.holdoutCV.plot <- knn.accu.kappa.plot(knn_model) +
  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), vjust = -1) +
  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), vjust = -1) +
  ggtitle("KNN Model Performance (Hold-out CV)")
```

##### Tuned
```{r knn.holdoutCV_mod, fig.show='hide'}
load("dataset\\knn.model_holdoutCV_mod.Rdata")

knn.predictions <- predict(knn_model, newdata = test)

confusionMatrix(knn.predictions, test$good)

knn.predictions <- as.numeric(knn.predictions)
pred_obj <- prediction(knn.predictions, test$good)
auc_val <- performance(pred_obj, "auc")@y.values[[1]]
auc_val

roc_obj <- performance(pred_obj, "tpr", "fpr")
plot(roc_obj, colorize = TRUE, lwd = 2,
     xlab = "False Positive Rate", 
     ylab = "True Positive Rate",
     main = "ROC Curves from Tuned Hold-out CV")
points(auc_val, 1 - auc_val, 
       col = "steelblue", 
       pch = 21)
abline(a = 0, b = 1)
knn.holdoutCV_mod.ROC.plot <- recordPlot()

knn.holdoutCV_mod.plot <- knn.accu.kappa.plot(knn_model) + 
  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), hjust = -0.3, angle=90) +
  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), hjust=-0.3, angle=90) +
  ggtitle("KNN Model Performance (Tuned Hold-out CV)")
```


#### LOOCV
```{r knn.LOOCV, fig.show='hide'}
load("dataset\\knn.model_looCV.Rdata")

knn.predictions <- predict(knn_model, newdata = test)
confusionMatrix(knn.predictions, test$good)

knn.predictions <- as.numeric(knn.predictions)
pred_obj <- prediction(knn.predictions, test$good)
auc_val <- performance(pred_obj, "auc")@y.values[[1]]
auc_val

roc_obj <- performance(pred_obj, "tpr", "fpr")
plot(roc_obj, colorize = TRUE, lwd = 2,
     xlab = "False Positive Rate", 
     ylab = "True Positive Rate",
     main = 'ROC Curves from LOOCV')
points(auc_val, 1 - auc_val, 
       col = "steelblue", 
       pch = 21)
abline(a = 0, b = 1)
knn.looCV.ROC.plot <- recordPlot()

knn.looCV.plot <- knn.accu.kappa.plot(knn_model) + 
  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), vjust = -1) +
  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), vjust = -1) +
  ggtitle("KNN Model Performance (LOOCV)")
```

##### Tuned
```{r knn.LOOCV_mod, fig.show='hide'}
load("dataset\\knn.model_looCV_mod.Rdata")

knn.predictions <- predict(knn_model, newdata = test)
confusionMatrix(knn.predictions, test$good)

knn.predictions <- as.numeric(knn.predictions)
pred_obj <- prediction(knn.predictions, test$good)
auc_val <- performance(pred_obj, "auc")@y.values[[1]]
auc_val

roc_obj <- performance(pred_obj, "tpr", "fpr")
plot(roc_obj, colorize = TRUE, lwd = 2,
     xlab = "False Positive Rate", 
     ylab = "True Positive Rate",
     main = "ROC Curves from Tuned LOOCV")
points(auc_val, 1 - auc_val, 
       col = "steelblue", 
       pch = 21)
abline(a = 0, b = 1)
knn.looCV_mod.ROC.plot <- recordPlot()

knn.looCV_mod.plot <- knn.accu.kappa.plot(knn_model) + 
  geom_text(aes(x = k, y = Accuracy, label = round(Accuracy, 3)), hjust = -0.3, angle=90) +
  geom_text(aes(x = k, y = Kappa, label = round(Kappa, 3)), hjust = -0.3, angle=90) +
  ggtitle("KNN Model Performance (Tuned LOOCV)")
```


#### Repeated CV
```{r knn.repeatedCV, fig.show='hide'}
load("dataset\\knn.model_repeatedCV.Rdata")

knn.predictions <- predict(knn_model, newdata = test)

confusionMatrix(knn.predictions, test$good)

knn.predictions <- as.numeric(knn.predictions)
pred_obj <- prediction(knn.predictions, test$good)
auc_val <- performance(pred_obj, "auc")@y.values[[1]]
auc_val

roc_obj <- performance(pred_obj, "tpr", "fpr")
plot(roc_obj, colorize = TRUE, lwd = 2,
     xlab = "False Positive Rate", 
     ylab = "True Positive Rate",
     main = "ROC Curves from Repeated CV")
points(auc_val, 1 - auc_val, 
       col = "steelblue", 
       pch = 21)
abline(a = 0, b = 1)
knn.repeatedCV.ROC.plot <- recordPlot()

df <- knn_model$results
knn.repeatedCV.plot <- ggplot(data=df, aes(x = kmax, y = Accuracy)) +
  geom_point(aes(color = "Accuracy")) +
  geom_point(aes(color = "Kappa")) +
  geom_line(aes(linetype = "Accuracy", color = "Accuracy")) +
  geom_line(aes(y = Kappa, linetype = "Kappa", color = "Kappa")) +
  geom_text(aes(label = round(Accuracy, 3)), vjust = -1) +
  geom_text(aes(y = Kappa, label = round(Kappa, 3)), vjust = -1) +
  scale_color_manual(values = c("#98c379", "#e06c75"),
                     guide = guide_legend(override.aes = list(linetype = c(1, 0)) )) +
  scale_linetype_manual(values=c("solid", "dotted"),
                        guide = guide_legend(override.aes = list(color = c("#98c379", "#e06c75")))) +
  labs(x = "K value", 
       y = "Accuracy / Kappa",
       title = "KNN Model Performance (Repeated CV)") +
  ylim(0, 1) +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5)) +
  guides(color = guide_legend(title = "Metric"),
         linetype = guide_legend(title = "Metric"))
```

##### Tuned
```{r knn.repeatedCV_mod, fig.show='hide'}
load("dataset\\knn.model_repeatedCV_mod.Rdata")

knn.predictions <- predict(knn_model, newdata = test)

confusionMatrix(knn.predictions, test$good)

knn.predictions <- as.numeric(knn.predictions)
pred_obj <- prediction(knn.predictions, test$good)
auc_val <- performance(pred_obj, "auc")@y.values[[1]]
auc_val

roc_obj <- performance(pred_obj, "tpr", "fpr")

plot(roc_obj, colorize = TRUE, lwd = 2,
     xlab = "False Positive Rate", 
     ylab = "True Positive Rate",
     main = "ROC Curves from Tuned Repeated CV")
points(auc_val, 1 - auc_val, 
       col = "steelblue", 
       pch = 21)
abline(a = 0, b = 1)
knn.repeatedCV_mod.ROC.plot <- recordPlot()

knn.repeatedCV_mod.plot <- ggplot(knn_model) +
  labs(x = "K value", 
       y = "Accuracy", 
       title = "KNN Model Performance (Tuned Repeated CV)") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5)) 
```


#### Summary

```{r knn.Accuracy.Kappa.Plot, fig.width=15, fig.height=20}
ggarrange(knn.kfoldCV.plot,
          knn.kfoldCV_mod.plot,
          knn.holdoutCV.plot,
          knn.holdoutCV_mod.plot,
          knn.looCV.plot,
          knn.looCV_mod.plot,
          knn.repeatedCV.plot,
          knn.repeatedCV_mod.plot,
          ncol = 2, nrow = 4)
```

```{r knn.ROC_curve, fig.width=10}
cowplot::plot_grid(knn.kfoldCV.ROC.plot, knn.kfoldCV_mod.ROC.plot,
                   ncol = 2, align = "hv", scale = 0.8)
cowplot::plot_grid(knn.holdoutCV.ROC.plot, knn.holdoutCV_mod.ROC.plot,
                   ncol = 2, align = "hv", scale = 0.8)
cowplot::plot_grid(knn.looCV.ROC.plot, knn.looCV_mod.ROC.plot,
                   ncol = 2, align = "hv", scale = 0.8)
cowplot::plot_grid(knn.repeatedCV.ROC.plot, knn.repeatedCV_mod.ROC.plot,
                   ncol = 2, align = "hv", scale = 0.8)
```



| Resampling Method    | Error Rate | Sensitivity | Specificity | AUC       |
| -------------------- | ---------- | ----------- | ----------- | --------- |
| K-Fold CV            | 0.2273     | 0.9199      | 0.1883      | 0.5541001 |
| K-Fold CV (Tuned)    | 0.1995     | 0.9768      | 0.1004      | 0.5386181 |
| Hold-out CV          | 0.2222     | 0.9336      | 0.1590      | 0.5463051 |
| Hold-out CV  (Tuned) | 0.2022     | 0.9926      | 0.0251      | 0.5088642 |
| LOOCV                | 0.1717     | 0.9642      | 0.2887      | 0.6264379 |
| LOOCV (Tuned)        | 0.1995     | 0.9768      | 0.1004      | 0.5386181 |
| Repeated CV          | 0.1776     | 0.9104      | 0.4728      | 0.6916177 |
| Repeated CV (Tuned)  | 0.1120     | 0.9547      | 0.6234      | 0.7890601 |


```{r echo=FALSE}
remove(knn_model, df,
       knn.kfoldCV.plot,
       knn.kfoldCV_mod.plot,
       knn.holdoutCV.plot,
       knn.holdoutCV_mod.plot,
       knn.looCV.plot,
       knn.looCV_mod.plot,
       knn.repeatedCV.plot,
       knn.repeatedCV_mod.plot)
remove(pred_obj, roc_obj)
remove(auc_val, knn.predictions)
```


### Logistic Regression
#### Model Construction
```{r logit.model_savings, eval=FALSE}
#----------------------------#
#----Logistic Regression-----#
#----------------------------#

set.seed(1234)
# Define the training control object for 10-fold cross-validation
train_control <- trainControl(method = "cv", number = 10)

# Train the logistic regression model using 10-fold cross-validation
set.seed(1234)
logit_model <- train(good ~ ., 
                     data = train, 
                     method = "glm", 
                     family = "binomial",
                     trControl = train_control)

save(logit_model, file = "dataset\\logit.model_kfoldCV.Rdata")


#----------------------------------#
#----Logistic Regression (Mod)-----#
#----------------------------------#

```

#### K-fold CV
```{r logit.kfoldCV, fig.show='hide', message=FALSE}
load("dataset\\logit.model_kfoldCV.Rdata")

logit.predictions <- predict(logit_model, newdata = test)

confusionMatrix(logit.predictions, test$good)


logit.predictions <- as.numeric(logit.predictions)
pred_obj <- prediction(logit.predictions, test$good)
auc_val  <- performance(pred_obj, "auc")@y.values[[1]]
auc_val

roc_obj <- performance(pred_obj, "tpr", "fpr")
plot(roc_obj, colorize = TRUE, lwd = 2,
     xlab = "False Positive Rate", 
     ylab = "True Positive Rate",
     main = "ROC Curves from Repeated CV")
points(auc_val, 1 - auc_val, 
       col = "steelblue", 
       pch = 21)
abline(a = 0, b = 1)
logit.kfoldCV.ROC.plot <- recordPlot()
```

##### Tuned
```{r logit.kfoldCV_mod}
glm.model <- glm(good ~ ., data= train,family="binomial")
glm.fit= stepAIC(glm.model, direction = 'backward')

# Make predictions on test data and construct a confusion matrix
logit.predictions <- predict(glm.fit, newdata = test,type = "response")
logit.predictions <- factor(ifelse(logit.predictions > 0.7, 1, 0),
                            levels = c(0, 1))
confusionMatrix(logit.predictions, test$good)


logit.predictions <- as.numeric(logit.predictions)
pred_obj <- prediction(logit.predictions, test$good)
auc_val <- performance(pred_obj, "auc")@y.values[[1]]
auc_val

roc_obj <- performance(pred_obj, "tpr", "fpr")
plot(roc_obj, colorize = TRUE, lwd = 2,
     xlab = "False Positive Rate", 
     ylab = "True Positive Rate",
     main = "ROC Curves from Repeated CV")
points(auc_val, 1 - auc_val, 
       col = "steelblue", 
       pch = 21)
abline(a = 0, b = 1)
logit.kfoldCV.ROC.plot <- recordPlot()
```

| Resampling Method           | Error Rate | Sensitivity | Specificity | AUC       |
| --------------------------- | ---------- | ----------- | ----------- | --------- |
| Logistic Regression         | 0.1944     | 0.9347      | 0.2929      | 0.6137776 |
| Logistic Regression (Tuned) | 0.1919     | 0.98946     | 0.08787     | 0.5386644 |


### Linear Discriminant Analysis

#### Model Construction
```{r lda.model_savings, eval=FALSE}
#------------#
#----LDA-----#
#------------#
set.seed(1234)
train_control <- trainControl(method = "cv", number = 10)

set.seed(1234)
lda_model <- train(good ~ ., 
                   data = train, 
                   method = "lda", 
                   trControl = train_control)

save(lda_model, file = "dataset\\lda.model_kfoldCV.Rdata")


#------------------#
#----LDA (Mod)-----#
#------------------#
```

#### K-fold CV
```{r lda.kfoldCV, fig.show='hide'}
load("dataset\\lda.model_kfoldCV.Rdata")

lda.predictions <- predict(lda_model, newdata = test)

confusionMatrix(lda.predictions, test$good)


lda.predictions <- as.numeric(lda.predictions)
pred_obj <- prediction(lda.predictions, test$good)
auc_val <- performance(pred_obj, "auc")@y.values[[1]]
auc_val

roc_obj <- performance(pred_obj, "tpr", "fpr")
plot(roc_obj, colorize = TRUE, lwd = 2,
     xlab = "False Positive Rate", 
     ylab = "True Positive Rate",
     main = "ROC Curves from Repeated CV")
points(auc_val, 1 - auc_val, 
       col = "steelblue", 
       pch = 21)
abline(a = 0, b = 1)
lda.kfoldCV.ROC.plot <- recordPlot()
```

##### Tuned
```{r, lda.kfoldCV_mod, fig.show='hide'}

```

| Resampling Method | Error Rate | Sensitivity | Specificity | AUC       |
| ----------------- | ---------- | ----------- | ----------- | --------- |
| LDA               | 0.1919     | 0.9283      | 0.3305      | 0.6294448 |
| LDA (Tuned)       | 0.xxxx     | 0.xxxx      | 0.xxxx      | 0.xxxxxxx |


### Quadratic discriminant analysis

#### Model Construction
```{r qda.model_savings, eval=FALSE}
#------------#
#----QDA-----#
#------------#
set.seed(1234)
train_control <- trainControl(method = "cv", number = 10)

set.seed(1234)
qda_model <- train(good ~ ., 
                   data = train, 
                   method = "qda", 
                   trControl = train_control)

save(qda_model, file = "dataset\\qda.model_kfoldCV.Rdata")

#------------------#
#----QDA (Mod)-----#
#------------------#
```

#### K-fold CV
```{r qda.kfoldCV, fig.show='hide'}
load("dataset\\qda.model_kfoldCV.Rdata")

qda.predictions <- predict(qda_model, newdata = test)

confusionMatrix(qda.predictions, test$good)


qda.predictions <- as.numeric(qda.predictions)
pred_obj <- prediction(qda.predictions, test$good)
auc_val <- performance(pred_obj, "auc")@y.values[[1]]
auc_val

roc_obj <- performance(pred_obj, "tpr", "fpr")
plot(roc_obj, colorize = TRUE, lwd = 2,
     xlab = "False Positive Rate", 
     ylab = "True Positive Rate",
     main = "ROC Curves from Repeated CV")
points(auc_val, 1 - auc_val, 
       col = "steelblue", 
       pch = 21)
abline(a = 0, b = 1)
qda.kfoldCV.ROC.plot <- recordPlot()
```

##### Tuned
```{r qda.kfoldCV_mod}

```

| Resampling Method | Error Rate | Sensitivity | Specificity | AUC       |
| ----------------- | ---------- | ----------- | ----------- | --------- |
| QDA               | 0.2559     | 0.7418      | 0.7531      | 0.7474858 |
| QDA (Tuned)       | 0.xxxx     | 0.xxxx      | 0.xxxx      | 0.xxxxxxx |


### Summary

```{r log.lda.qda.ROC_curve, fig.width=10, fig.height=10}
cowplot::plot_grid(knn.kfoldCV.ROC.plot,
                   logit.kfoldCV.ROC.plot,
                   lda.kfoldCV.ROC.plot,
                   qda.kfoldCV.ROC.plot, 
                   ncol = 2, align = "hv", scale = 0.8)
```


| Resampling Method           | Error Rate | Sensitivity | Specificity | AUC       |
| --------------------------- | ---------- | ----------- | ----------- | --------- |
| Logistic Regression         | 0.1944     | 0.9347      | 0.2929      | 0.6137776 |
| Logistic Regression (Tuned) | 0.1919     | 0.98946     | 0.08787     | 0.5386644 |
|                             |            |             |             |           |
| LDA                         | 0.1919     | 0.9283      | 0.3305      | 0.6294448 |
| LDA (Tuned)                 | 0.xxxx     | 0.xxxx      | 0.xxxx      | 0.xxxxxxx |
|                             |            |             |             |           |
| QDA                         | 0.2559     | 0.7418      | 0.7531      | 0.7474858 |
| QDA (Tuned)                 | 0.xxxx     | 0.xxxx      | 0.xxxx      | 0.xxxxxxx |


## Furthuer Modeling

### Naive Bayes

#### Model Construction
```{r}

```

#### K-fold CV
```{r}

```

##### Tuned
```{r}

```

### Decision Tree

#### Model Construction
```{r}
set.seed(1234)


```

#### K-fold CV
```{r}

```

##### Tuned
```{r}

```



### Randome Forest

#### Model Construction
```{r}
set.seed(1234)


```

#### K-fold CV
```{r}

```

##### Tuned
```{r}

```


### Bagging

#### Model Construction
```{r}
set.seed(1234)


```

#### K-fold CV
```{r}

```

##### Tuned
```{r}

```


### Boosting

#### Model Construction
```{r}
set.seed(1234)


```

#### K-fold CV
```{r}

```

##### Tuned
```{r}

```

### SVM

#### Model Construction
```{r}
set.seed(1234)


```

#### K-fold CV
```{r}

```

##### Tuned
```{r}

```

### Summary

